{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSm0ju9puyiP"
      },
      "source": [
        "Предварительно про PyTorch:\n",
        "* [Про тензоры в pytorch](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/tensor_tutorial.ipynb)\n",
        "* [Про автоматическое дифференцирование и что такое .backwards()](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/autograd_tutorial.ipynb)\n",
        "* [Очень простая нейронка на pytorch](https://colab.research.google.com/drive/1RsZvw4KBGn5U5Aj5Ak7OG2pHx6z1OSlF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcgMmb-QuyiT"
      },
      "source": [
        "#Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EQ4-xO7uyiU",
        "outputId": "19d34fc6-fa05-48ed-9d6d-7603d526ae38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-09 07:34:37--  https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1253562 (1.2M) [text/plain]\n",
            "Saving to: ‘Constraint_Train.csv.1’\n",
            "\n",
            "Constraint_Train.cs 100%[===================>]   1.20M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-05-09 07:34:37 (55.6 MB/s) - ‘Constraint_Train.csv.1’ saved [1253562/1253562]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YCpo8FuuyiW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NSv9Mo9X-tT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Constraint_Train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hgpfPhA0uyiX",
        "outputId": "4bcc0800-0e20-48cd-ed26-8b28c1cb2030"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              tweet label\n",
              "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
              "1   2  States reported 1121 deaths a small rise from ...  real\n",
              "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4   5  Populous states can generate large case counts...  real"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f6de7d9-5394-45f1-a920-857ed5c38ef6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f6de7d9-5394-45f1-a920-857ed5c38ef6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f6de7d9-5394-45f1-a920-857ed5c38ef6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f6de7d9-5394-45f1-a920-857ed5c38ef6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSc9uNipR_Wf"
      },
      "source": [
        "# Методы sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvIJ0OrDpA1G"
      },
      "source": [
        "## модели из лекции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QVUEiLfuyiY"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HbHy4nVNKtt",
        "outputId": "2b034ae6-339f-4fb1-bdec-0d0e59221a2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO62Fv2YuyiY",
        "outputId": "8a532fb1-ee76-49e3-fbd9-5bf3c9c237d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6420/6420 [00:02<00:00, 2950.80it/s]\n"
          ]
        }
      ],
      "source": [
        "sentences = [word_tokenize(text.lower()) for text in tqdm(df.tweet)] # токенизируем текст"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hre12jbFRiWy"
      },
      "source": [
        "### __model__ (Word2vec + LogisticRegression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV6DsOOPuyiZ",
        "outputId": "850cf223-c8d5-4a26-fe11-147a1677dcef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 8.48 s, sys: 45.1 ms, total: 8.52 s\n",
            "Wall time: 4.64 s\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.word2vec import Word2Vec # векторизуем тексты с помощью словарных эмбендингов\n",
        "%time model_tweets = Word2Vec(sentences, workers=4, vector_size=300, min_count=3, window=5, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0crXwloIqGC",
        "outputId": "b3ae7950-a250-4833-f865-1eb251754935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('cure', 0.7973955273628235),\n",
              " ('drug', 0.7808627486228943),\n",
              " ('scientists', 0.7612375617027283),\n",
              " ('developed', 0.7383346557617188),\n",
              " ('fight', 0.7292054295539856),\n",
              " ('pandemic', 0.7139097452163696),\n",
              " ('against', 0.7109015583992004),\n",
              " ('remedy', 0.7073735594749451),\n",
              " ('company', 0.7011401653289795),\n",
              " ('novel', 0.6907817125320435)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_tweets.wv.most_similar('vaccine') # проверка на адекватность - смотрим близкие слова к слову \"вакцина\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmqe5t6BuyiZ",
        "outputId": "95d2b7f7-d824-4dde-9bf8-ff95f4019c34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('isolation', 0.945399820804596),\n",
              " ('managed', 0.9424483776092529),\n",
              " ('facility', 0.8861786127090454),\n",
              " ('auckland', 0.8855910301208496),\n",
              " ('facilities', 0.8798918128013611),\n",
              " ('cluster', 0.829450786113739),\n",
              " ('christchurch', 0.818962812423706),\n",
              " ('hospitals', 0.7934414744377136),\n",
              " ('border', 0.7895841598510742),\n",
              " ('none', 0.7835988998413086)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_tweets.wv.most_similar('quarantine') # проверка на адекватность - смотрим близкие слова к слову \"карантин\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1C2ivBwuyia"
      },
      "outputs": [],
      "source": [
        "model_tweets.init_sims() # нормируем вектора, чтобы они были в одинаковом пространстве"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gegRNK8fuyib"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aQM-6_Cuyib"
      },
      "outputs": [],
      "source": [
        "def get_text_embedding(text):\n",
        "    \"\"\"создать эмбединг текста\"\"\"\n",
        "    result = []\n",
        "    for word in word_tokenize(text.lower()):\n",
        "        if word in model_tweets.wv:\n",
        "            result.append(model_tweets.wv[word])\n",
        "\n",
        "    if len(result):\n",
        "        result = np.sum(result, axis=0)\n",
        "    else:\n",
        "        result = np.zeros(300)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEXHIkb7uyib",
        "outputId": "b822abab-528d-46d0-9327-6080a5d53d49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6420/6420 [00:02<00:00, 2287.67it/s]\n"
          ]
        }
      ],
      "source": [
        "features = [get_text_embedding(text) for text in tqdm(df.tweet)] # вектора признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYWbsK2Duyic"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45OhRwtTuyic"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, df.label, test_size=0.33, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_JNAMZ2uyic"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(random_state=0)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrWxWWhmuyic"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSBQINBVuyid"
      },
      "outputs": [],
      "source": [
        "predicted = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh8xvZ-nuyid",
        "outputId": "24756ca2-1104-4392-cc4f-644afdca3afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake      0.906     0.917     0.912      1018\n",
            "        real      0.923     0.912     0.917      1101\n",
            "\n",
            "    accuracy                          0.915      2119\n",
            "   macro avg      0.914     0.915     0.914      2119\n",
            "weighted avg      0.915     0.915     0.915      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predicted, digits = 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5qCQpNduyid"
      },
      "source": [
        "### __model_1__ (CountVectorizer + LogisticRegression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKLUWP8huyie"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY2CQW0wuyie"
      },
      "outputs": [],
      "source": [
        "vec = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7CxqeGwuyie"
      },
      "outputs": [],
      "source": [
        "bow = vec.fit_transform(df.tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVzRicjKuyif"
      },
      "outputs": [],
      "source": [
        "X1_train, X1_test, y1_train, y1_test = train_test_split(bow, df.label, test_size=0.33, random_state=0)\n",
        "model_1 = LogisticRegression(random_state=0)\n",
        "model_1.fit(X1_train, y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMowWWtnuyif",
        "outputId": "c4a9c19f-f99f-41d6-c275-f424d632e1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.93      0.93      0.93      1018\n",
            "        real       0.93      0.93      0.93      1101\n",
            "\n",
            "    accuracy                           0.93      2119\n",
            "   macro avg       0.93      0.93      0.93      2119\n",
            "weighted avg       0.93      0.93      0.93      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predicted_1 = model_1.predict(X1_test)\n",
        "print(classification_report(y1_test, predicted_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BGmDx2wpuv5"
      },
      "source": [
        "## мои модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEjo9InUb63V"
      },
      "source": [
        "### __model_1_clean__  без стоп-слов (CountVectorizer + LogisticRegression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ju24kigXo6U",
        "outputId": "09998c2b-e279-4022-b9a9-d22f6ce532ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X9nMmvsrcxm",
        "outputId": "9716a5fc-b60f-4382-f0ae-56c1e30e2d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HyhF13B1T4my",
        "outputId": "340248d2-de27-4f8e-e0c4-f311a7bd74c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from string import punctuation\n",
        "punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIUMuLRLYmyW"
      },
      "outputs": [],
      "source": [
        "noise = stopwords.words('english') + list(punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR4LP9Vyb63Z",
        "outputId": "0e426295-c802-4e32-b86a-f7f128d57fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.93      0.94      0.93      1018\n",
            "        real       0.94      0.93      0.94      1101\n",
            "\n",
            "    accuracy                           0.94      2119\n",
            "   macro avg       0.94      0.94      0.94      2119\n",
            "weighted avg       0.94      0.94      0.94      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vec_1 = CountVectorizer(stop_words=noise)\n",
        "bow_1 = vec_1.fit_transform(df.tweet)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(bow_1, df.label, test_size=0.33, random_state=0)\n",
        "model_1_clean = LogisticRegression(random_state=0)\n",
        "model_1_clean.fit(X2_train, y2_train)\n",
        "predicted_2 = model_1_clean.predict(X2_test)\n",
        "print(classification_report(y2_test, predicted_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frpClF6szwgl"
      },
      "source": [
        "### __ppl_clf_1__  (CountVectorizer + TfidfTransformer + TruncatedSVD + LogisticRegression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XCR75CZ4xE4",
        "outputId": "d3de5afb-0114-4740-f588-e2257f3c79b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6420 entries, 0 to 6419\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      6420 non-null   int64 \n",
            " 1   tweet   6420 non-null   object\n",
            " 2   label   6420 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 150.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frAlDbV8F2e-",
        "outputId": "a4cdaea5-8f21-43a4-dd3e-0e7046a09130"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "real    3360\n",
              "fake    3060\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.label.value_counts(dropna=False) # смотрим сбалансированность данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lA9oIoK_7jd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkxS8alAjcTB"
      },
      "outputs": [],
      "source": [
        "le.fit(df.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn26w8unE-Lt",
        "outputId": "04c4229f-01cc-4257-bfe0-171f7bc3fdfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.transform( ['real', 'fake']) # пример расшифровки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV9Klc1XG8ms",
        "outputId": "9f5e7712-8b14-4f0e-fc2f-3e1838f93b89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = pd.Series (le.transform(df.label))\n",
        "y.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSn3d1TpAsXK"
      },
      "outputs": [],
      "source": [
        "X=df.tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMFKB7UN4V2h"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90tfObp35wXR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax8iNLNtBNJX",
        "outputId": "ba3401ef-6c70-489d-a6dc-0ed1eb863f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6420\n",
            "(4301,)\n",
            "(2119,)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape[0])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2CeDXT9RO0j"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQZs9cRBCaXK"
      },
      "outputs": [],
      "source": [
        "ppl_clf_1 = Pipeline([\n",
        "    ('vect', CountVectorizer(stop_words=noise)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('tm', TruncatedSVD(n_components=100)),\n",
        "    ('clf', LogisticRegression(random_state=0))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRvLfsxADTnm"
      },
      "outputs": [],
      "source": [
        "ppl_clf_1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9724W2yvuwN",
        "outputId": "3923631a-b333-4a89-9ba7-92fbfba2c13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.87      0.91      0.89       980\n",
            "        real       0.92      0.89      0.90      1139\n",
            "\n",
            "    accuracy                           0.90      2119\n",
            "   macro avg       0.89      0.90      0.89      2119\n",
            "weighted avg       0.90      0.90      0.90      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred_ppl_clf_1 = ppl_clf_1.predict(X_test)\n",
        "print(classification_report(pred_ppl_clf_1, y_test, target_names=['fake', 'real']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQSZh2MxEqNp",
        "outputId": "63f2784e-fc1d-48f7-9893-8b2f7f001764"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'tm', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'tm__algorithm', 'tm__n_components', 'tm__n_iter', 'tm__n_oversamples', 'tm__power_iteration_normalizer', 'tm__random_state', 'tm__tol', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__l1_ratio', 'clf__max_iter', 'clf__multi_class', 'clf__n_jobs', 'clf__penalty', 'clf__random_state', 'clf__solver', 'clf__tol', 'clf__verbose', 'clf__warm_start'])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ppl_clf_1.get_params().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZlBsE_y4Tyw"
      },
      "source": [
        "Далее подбираю оптимальные параметры, делаю это частями, иначе слишком долго отрабатывается код (более 2.5часов на GPU), колаб постоянно меня выкидывает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2SWYxwZhggh",
        "outputId": "57fb934c-61ae-48ce-9d01-6e2fd3c8dca9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "576 fits failed out of a total of 4032.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "576 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_truncated_svd.py\", line 237, in fit_transform\n",
            "    raise ValueError(\n",
            "ValueError: n_components(100) must be <= n_features(10).\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.88747039 0.88863188 0.88863318 ... 0.71867122 0.71750951 0.72215894]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Оптимальные параметры для grid1:\n",
            "0.9081604996974151 {'vect__max_df': 0.95, 'vect__max_features': None, 'vect__min_df': 3, 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'], 'vect__strip_accents': 'unicode'}\n"
          ]
        }
      ],
      "source": [
        "hyperparams_1 = {\n",
        "    'vect__ngram_range': [(1, 1), (2, 2), (3, 3)],\n",
        "    'vect__max_df': [0.85, 0.95],\n",
        "    'vect__min_df': [1,2,3,4],\n",
        "    'vect__stop_words': [None, noise],\n",
        "    'vect__max_features': [None, 10, 100, 500, 1000, 5000, 10000],\n",
        "    'vect__strip_accents': ['ascii', 'unicode', None],\n",
        "}\n",
        "\n",
        "grid1 = GridSearchCV(ppl_clf_1, hyperparams_1, cv=4, n_jobs=-1).fit(X_train, y_train)\n",
        "print('Оптимальные параметры для grid1:')\n",
        "print(grid1.best_score_, grid1.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSSMZCji3lQ_"
      },
      "outputs": [],
      "source": [
        "noise_cor = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXddI3K6rj2L"
      },
      "outputs": [],
      "source": [
        "ppl_clf_1 = Pipeline([\n",
        "    ('vect', CountVectorizer(max_df=0.95, max_features=None, min_df=3, ngram_range=(1, 1), stop_words=noise_cor, strip_accents='unicode')),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('tm', TruncatedSVD(n_components=100)),\n",
        "    ('clf', LogisticRegression(random_state=0))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72r_F9Xmrj2M"
      },
      "outputs": [],
      "source": [
        "ppl_clf_1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocWWxRESrj2O",
        "outputId": "f3bdb00a-6ca1-446b-b5d2-ab026ff56284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.89      0.90      0.89      1009\n",
            "        real       0.90      0.90      0.90      1110\n",
            "\n",
            "    accuracy                           0.90      2119\n",
            "   macro avg       0.90      0.90      0.90      2119\n",
            "weighted avg       0.90      0.90      0.90      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred_ppl_clf_1 = ppl_clf_1.predict(X_test)\n",
        "print(classification_report(pred_ppl_clf_1, y_test, target_names=['fake', 'real']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHfcKsauE2Fs",
        "outputId": "96659dfb-5ea1-4c9e-f148-a064ebd15115"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "216 fits failed out of a total of 480.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1223, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1062, in _get_liblinear_solver_type\n",
            "    raise ValueError(\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "24 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.898395   0.91281123 0.91164757 0.89955931 0.90978797 0.91467148\n",
            "        nan        nan        nan 0.89862821 0.91071842 0.90978992\n",
            " 0.90025504 0.90862497 0.90676688 0.86398396 0.90095271 0.91327548\n",
            " 0.86142604 0.90281231 0.91025504 0.86096222 0.90351063 0.91071821\n",
            " 0.86282117 0.90351063 0.91327699 0.86351928 0.90258083 0.90676688\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.86607872 0.90048738 0.91397316        nan        nan        nan\n",
            " 0.86747255 0.90164952 0.90699901        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.89816288 0.90862583 0.91490382 0.89723481 0.9109512  0.91234525\n",
            "        nan        nan        nan 0.89862821 0.91257932 0.90769538\n",
            " 0.9025804  0.90955628 0.90606921 0.87421436 0.90118548 0.91350826\n",
            " 0.87142604 0.90258062 0.91559998 0.87398288 0.90188294 0.91350804\n",
            " 0.8732865  0.90258062 0.911881   0.87421544 0.90095249 0.90606964\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.86933366 0.89979035 0.91257932        nan        nan        nan\n",
            " 0.8693341  0.90537045 0.90792859        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Оптимальные параметры для grid1:\n",
            "0.915599982709432 {'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'tfidf__norm': None}\n"
          ]
        }
      ],
      "source": [
        "hyperparams_1 = {\n",
        "    'tfidf__norm': ['l1', 'l2', None],\n",
        "    'clf__class_weight':[None, 'balanced'],\n",
        "    'clf__penalty':[None, 'l2', 'l1', 'elasticnet'],\n",
        "    'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "}\n",
        "\n",
        "grid1 = GridSearchCV(ppl_clf_1, hyperparams_1, cv=4, n_jobs=-1).fit(X_train, y_train)\n",
        "print('Оптимальные параметры для grid1:')\n",
        "print(grid1.best_score_, grid1.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcmLy7lv8OlF"
      },
      "outputs": [],
      "source": [
        "ppl_clf_1 = Pipeline([\n",
        "    ('vect', CountVectorizer(max_df=0.95, max_features=None, min_df=3, ngram_range=(1, 1), stop_words=noise_cor, strip_accents='unicode')),\n",
        "    ('tfidf', TfidfTransformer(norm=None)),\n",
        "    ('tm', TruncatedSVD(n_components=100)),\n",
        "    ('clf', LogisticRegression(class_weight='balanced', penalty='l2', solver='lbfgs', random_state=0))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnD855rk8OlG"
      },
      "outputs": [],
      "source": [
        "ppl_clf_1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdCPj5Sc8OlH",
        "outputId": "2c5869cd-13e5-4fc0-df6d-440e66a49ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake      0.924     0.896     0.910      1050\n",
            "        real      0.901     0.928     0.914      1069\n",
            "\n",
            "    accuracy                          0.912      2119\n",
            "   macro avg      0.913     0.912     0.912      2119\n",
            "weighted avg      0.913     0.912     0.912      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred_ppl_clf_1 = ppl_clf_1.predict(X_test)\n",
        "print(classification_report(pred_ppl_clf_1, y_test, target_names=['fake', 'real'], digits = 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oBhYyf6dKZI"
      },
      "source": [
        "### RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr1O28ww_Rk0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-dXN-9WPJOd"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuQ_Hhu0QqZj"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV3tMjDyI8Ck"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3ycyeU-N72v"
      },
      "outputs": [],
      "source": [
        "models=[\n",
        "      {'name':'Lr',\"model\": LogisticRegression(random_state=0),\n",
        "       'params':\n",
        "              {'C':np.linspace(0, 10, 5),\n",
        "                'penalty':['l1', 'l2', 'elasticnet', 'none'],\n",
        "                'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "              }\n",
        "      },\n",
        "      {'name':'SVC',\"model\": SVC(random_state=0),\n",
        "       'params':\n",
        "              {'C': np.linspace(0, 10, 5),\n",
        "               'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "               'degree':[1,2,3,5]\n",
        "               }\n",
        "       },\n",
        "      {'name':'RF',\"model\": RandomForestClassifier(random_state=0),\n",
        "       'params':\n",
        "              {'n_estimators':[10,25,50,100,150,200],\n",
        "               'criterion':['gini', 'entropy'],\n",
        "               'max_depth':[3,5,7,9,11],\n",
        "               'min_samples_leaf':[1,2,3,5]\n",
        "               }\n",
        "       },\n",
        "      {'name':'KNN',\"model\": KNeighborsClassifier(),\n",
        "       'params':\n",
        "              {'n_neighbors':list(range(1,30)),\n",
        "               'weights': ['uniform', 'distance'],\n",
        "               'p':[1,2,3],\n",
        "               'metric':['euclidean', 'minkowski']\n",
        "               }\n",
        "       },\n",
        "      {'name':'DT',\"model\": DecisionTreeClassifier(random_state=0),\n",
        "       'params':\n",
        "              {'criterion':['gini', 'entropy'],\n",
        "               'max_depth':[3,5,7,9,11],\n",
        "               'min_samples_split':[2,3,4,5,7,9],\n",
        "               'min_samples_leaf':[1,2,3,5]\n",
        "               }\n",
        "       }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVzI1N5HP3Ah",
        "outputId": "e01683df-04ad-4bec-a0d6-5b8f9c485759"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [03:07<00:00, 37.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3min, sys: 1min 11s, total: 4min 11s\n",
            "Wall time: 3min 7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "res = []\n",
        "for v in tqdm(models):\n",
        "    res.append((v['name'], RandomizedSearchCV(v['model'], v['params'],cv=4, random_state=0).fit(X2_train, y2_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0YHFkQGQi7w",
        "outputId": "0c238cd9-1275-4bf5-efb5-c3ab106a0fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lr 0.9269942508861415 {'solver': 'lbfgs', 'penalty': 'l2', 'C': 2.5}\n",
            "SVC 0.9246684533586929 {'kernel': 'rbf', 'degree': 5, 'C': 2.5}\n",
            "RF 0.8890939742370537 {'n_estimators': 200, 'min_samples_leaf': 2, 'max_depth': 11, 'criterion': 'entropy'}\n",
            "KNN 0.7551726895478517 {'weights': 'distance', 'p': 2, 'n_neighbors': 8, 'metric': 'euclidean'}\n",
            "DT 0.8667733638800035 {'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 11, 'criterion': 'gini'}\n"
          ]
        }
      ],
      "source": [
        "for r in res:\n",
        "    print(r[0], r[1].best_score_, r[1].best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE4AyWcLlzKi"
      },
      "source": [
        "#### model_1_clean_1 (CountVectorizer + SVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNO8QNJf7RXX",
        "outputId": "43058aa9-d478-4ac6-af24-6a3a00216070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.94      0.92      0.93      1018\n",
            "        real       0.93      0.95      0.94      1101\n",
            "\n",
            "    accuracy                           0.94      2119\n",
            "   macro avg       0.94      0.94      0.94      2119\n",
            "weighted avg       0.94      0.94      0.94      2119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_1_clean_1 = SVC(kernel='rbf', degree=5, C=2.5, random_state=0)\n",
        "model_1_clean_1.fit(X2_train, y2_train)\n",
        "predicted_3 = model_1_clean_1.predict(X2_test)\n",
        "print(classification_report(y2_test, predicted_3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdUFofQORJYU"
      },
      "source": [
        "## сводная таблица по моделям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvHHmiu9SgzH"
      },
      "outputs": [],
      "source": [
        "report = classification_report(y_test, predicted, output_dict=True)\n",
        "df_r = pd.DataFrame(report)\n",
        "test=pd.Series(round(df_r[2:3]['macro avg'],3), name='model (Word2vec + LogisticRegression)')\n",
        "test=pd.DataFrame(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEIW8niMT5av"
      },
      "outputs": [],
      "source": [
        "report_1 = classification_report(y1_test, predicted_1, output_dict=True)\n",
        "df_r_1 = pd.DataFrame(report_1)\n",
        "test_1=pd.Series(round(df_r_1[2:3]['macro avg'],3), name='model_1 (CountVectorizer + LogisticRegression)')\n",
        "test_1=pd.DataFrame(test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw9njiT9U_Pt"
      },
      "outputs": [],
      "source": [
        "report_2 = classification_report(y2_test, predicted_2, output_dict=True)\n",
        "df_r_2 = pd.DataFrame(report_2)\n",
        "test_2=pd.Series(round(df_r_2[2:3]['macro avg'],3), name='model_1_clean без стоп-слов (CountVectorizer + LogisticRegression)')\n",
        "test_2=pd.DataFrame(test_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5Q45viRbwjC"
      },
      "outputs": [],
      "source": [
        "report_3 = classification_report(y_test, pred_ppl_clf_1, output_dict=True)\n",
        "df_r_3 = pd.DataFrame(report_3)\n",
        "test_3=pd.Series(round(df_r_3[2:3]['macro avg'],3), name='ppl_clf_1 (CountVectorizer + TfidfTransformer + TruncatedSVD + LogisticRegression)')\n",
        "test_3=pd.DataFrame(test_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaUUl944nJQ6"
      },
      "outputs": [],
      "source": [
        "report_4 = classification_report(y2_test, predicted_3, output_dict=True, digits = 3)\n",
        "df_r_4 = pd.DataFrame(report_4)\n",
        "test_4=pd.Series(round(df_r_4[2:3]['macro avg'],3), name='model_1_clean_1 (CountVectorizer + SVC)')\n",
        "test_4=pd.DataFrame(test_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAD-PrsPSm2b"
      },
      "outputs": [],
      "source": [
        "test_concat = pd.concat([test, test_1, test_2,test_3, test_4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "0N8ZyXBDqeXF",
        "outputId": "387d6cbb-9ce6-4e66-fa31-93325a8d988c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_4d095_row0_col2, #T_4d095_row0_col4 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_4d095\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_4d095_level0_col0\" class=\"col_heading level0 col0\" >model (Word2vec + LogisticRegression)</th>\n",
              "      <th id=\"T_4d095_level0_col1\" class=\"col_heading level0 col1\" >model_1 (CountVectorizer + LogisticRegression)</th>\n",
              "      <th id=\"T_4d095_level0_col2\" class=\"col_heading level0 col2\" >model_1_clean без стоп-слов (CountVectorizer + LogisticRegression)</th>\n",
              "      <th id=\"T_4d095_level0_col3\" class=\"col_heading level0 col3\" >ppl_clf_1 (CountVectorizer + TfidfTransformer + TruncatedSVD + LogisticRegression)</th>\n",
              "      <th id=\"T_4d095_level0_col4\" class=\"col_heading level0 col4\" >model_1_clean_1 (CountVectorizer + SVC)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_4d095_level0_row0\" class=\"row_heading level0 row0\" >f1-score</th>\n",
              "      <td id=\"T_4d095_row0_col0\" class=\"data row0 col0\" >0.914</td>\n",
              "      <td id=\"T_4d095_row0_col1\" class=\"data row0 col1\" >0.930</td>\n",
              "      <td id=\"T_4d095_row0_col2\" class=\"data row0 col2\" >0.936</td>\n",
              "      <td id=\"T_4d095_row0_col3\" class=\"data row0 col3\" >0.912</td>\n",
              "      <td id=\"T_4d095_row0_col4\" class=\"data row0 col4\" >0.936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f0a32f0a200>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_concat.style.format('{:.3f}').highlight_max(color = 'lightgreen', axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNb_PXk6EAHo"
      },
      "source": [
        "# Методы на PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6qOclJPuyif"
      },
      "source": [
        "## модель из лекции (PyTorch + LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHDxqZnTuyif"
      },
      "outputs": [],
      "source": [
        "labels = (df.label == 'real').astype(int).to_list() # переводим метки в числа"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf742XDZ5ig0",
        "outputId": "31e121d3-061a-4057-9d16-208703202992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 0, 1, 1]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fUz2OKauyif"
      },
      "source": [
        "Нужно заранее задать размер для макксимальной длины предложений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPSsE5JW6H9Z"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0kjhDmG6Pn2",
        "outputId": "dbc05f79-0339-4f2b-f4aa-410999ce81eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpgtHhWD8Zpf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BkQTxbMuyig"
      },
      "outputs": [],
      "source": [
        "token_lists = [word_tokenize(text.lower()) for text in df.tweet] # токенизируем тексты\n",
        "max_len = len(max(token_lists, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "125Q6tQhuyig",
        "outputId": "a5732cb9-4989-424b-fc46-9e4766b6853d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1592"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HUNPzqWuyig"
      },
      "source": [
        "Это слишком много. Но какая длина обычно?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TQVd6Fruyig"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "fd = Counter([len(tokens) for tokens in token_lists]) # смотрим какие длины чаще встречаются"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CycieWjbuyih",
        "outputId": "f34373ee-4a46-4611-b53d-1f06c8deae6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(20, 178),\n",
              " (25, 174),\n",
              " (22, 170),\n",
              " (18, 170),\n",
              " (19, 168),\n",
              " (21, 168),\n",
              " (16, 163),\n",
              " (17, 162),\n",
              " (15, 160),\n",
              " (23, 156)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fd.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LNWZldVuyih"
      },
      "source": [
        "Зададим максимум 200."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxPTNDQ0uyii"
      },
      "source": [
        "Возьмём те же w2v эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXYtPJNy7gab",
        "outputId": "49f49f6b-ec2d-4926-99d0-03134b92e26a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6420/6420 [00:01<00:00, 3311.59it/s]\n"
          ]
        }
      ],
      "source": [
        "sentences = [word_tokenize(text.lower()) for text in tqdm(df.tweet)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ7hM6OV7VC2",
        "outputId": "ccd44571-aaed-486f-8a27-3829291a6143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10.3 s, sys: 88.8 ms, total: 10.3 s\n",
            "Wall time: 7.08 s\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "%time model_tweets = Word2Vec(sentences, workers=4, vector_size=300, min_count=3, window=5, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNOPWCq1uyii"
      },
      "outputs": [],
      "source": [
        "def get_word_embedding(tokens, max_len):\n",
        "    result = []\n",
        "    for i in range(max_len):\n",
        "        if i < len(tokens):\n",
        "            word = tokens[i]\n",
        "            if word in model_tweets.wv:\n",
        "                result.append(model_tweets.wv[word])\n",
        "            else:\n",
        "                result.append(np.zeros(300))\n",
        "        else:\n",
        "            result.append(np.zeros(300))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBkyQdORuyii",
        "outputId": "d5d282dc-ddd4-4815-bd4b-23cd8a7f3629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6420/6420 [00:04<00:00, 1560.19it/s]\n"
          ]
        }
      ],
      "source": [
        "features = [get_word_embedding(text, 200) for text in tqdm(token_lists)] # список векторов каждого слова в тексте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwmO11dj8rXX"
      },
      "outputs": [],
      "source": [
        "features[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xDS3Iq29OO4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_COity4Puyij"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXHLD6eKuyij"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwGQpAbcuyij",
        "outputId": "75710115-1aaf-45a8-e57c-bd35dacd762f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(features[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNRDEXNRdOF",
        "outputId": "368d4e73-fac5-48e2-b262-9cffe09c81f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4301"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVsXkUfMRlc1",
        "outputId": "ba75bd9f-6616-4b8b-f3e3-970e5ce94cb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZuoO5uhRpmy",
        "outputId": "5e8e6b39-95af-4ff1-c7d4-bc148de49a21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOjKyQdnuyij",
        "outputId": "196353c6-2000-4fff-b466-a5f428b5098c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-02003c1debcb>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  in_data = torch.tensor(X_train).float()\n"
          ]
        }
      ],
      "source": [
        "in_data = torch.tensor(X_train).float()\n",
        "targets = torch.tensor(y_train).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Surg_PcQuyij",
        "outputId": "c9c56f62-2772-4b3b-c3fd-dae136e73236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4301, 200, 300])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "in_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-N2gN0xuyij",
        "outputId": "055f367f-2332-44ab-e927-d62b5ae301c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (lstm): LSTM(300, 100)\n",
            "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Сети с долговременной кратковременной памятью (LSTM) представляют собой особый вид RNN, которые способны изучать долгосрочные зависимости.\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(300, 100) # на вход - вектор размерностью 300, скрытый слой задали 100\n",
        "        self.out = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings, (shortterm, longterm) = self.lstm(x.transpose(0, 1)) # longterm - линейный слой долгосрочной памяти\n",
        "        prediction = torch.sigmoid(self.out(longterm))\n",
        "        return prediction\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ8WQFlnuyik"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujjn4KVIuyik"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(in_data, targets, batch_size=16):\n",
        "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
        "        batch_x = in_data[i:i + batch_size]\n",
        "        batch_y = targets[i:i + batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        output = net(batch_x)\n",
        "        loss = criterion(output.reshape(-1), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CorzeZjIuyik",
        "outputId": "12c106d1-76a0-4480-cc11-6d4d34ecc8e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:13<00:00,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6808, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_one_epoch(in_data, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pna8zQLluyil"
      },
      "source": [
        "Что получилось?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQGiiAiLuyil"
      },
      "outputs": [],
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VuVw4uUuyil"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = net(in_data_test).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJxlSn2buyil"
      },
      "outputs": [],
      "source": [
        "result = (output > 0.5) == targets_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTYoH6Xpuyil",
        "outputId": "59279d86-52ce-42e7-8ab0-cf835f9635dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5002359603586597"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.sum().item() / len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a-HEDe9uyim"
      },
      "source": [
        "Но такую модель надо учить дольше("
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7bJz8aKEZm0"
      },
      "source": [
        "## оптимизация модели из лекции"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiOPYUYkEjKX"
      },
      "source": [
        "### увеличиваем количество эпох до 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvJcMhcYEzwW",
        "outputId": "d50c3cda-9da2-4dbf-bb04-87e583cfd4ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:09<00:00,  1.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6796, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:20<00:00,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:35<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:07<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:20<00:00,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:15<00:00,  1.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:02<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:04<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:05<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [05:01<00:00,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6793, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  train_one_epoch(in_data, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnbelmIwFWMd"
      },
      "outputs": [],
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APGhybdpFWMe"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = net(in_data_test).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQyAIyxEFWMf"
      },
      "outputs": [],
      "source": [
        "result = (output > 0.5) == targets_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2Pf87_0FWMg",
        "outputId": "d3d8dee9-a3ca-44de-fead-ebf54ebf1c4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5002359603586597"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.sum().item() / len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcKJYstSH39f"
      },
      "source": [
        "### заменой оптимизатора на Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lZdml8lIR22"
      },
      "source": [
        "Замена оптимизатора SGD на оптимизатор __Rectified Adam PyTorch__.\n",
        "\n",
        "Исправленный оптимизатор Адама Pytorch — это альтернатива оптимизатору Адама, который пытается решить проблему плохой сходимости Адама.\n",
        "Он также используется для исправления изменений скорости адаптивного обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pP8dnYNKhG1"
      },
      "outputs": [],
      "source": [
        "optimizer_RAdam = optim.RAdam(net.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaV4pJc4d1aX"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMpWsp-VKhG3"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch_RAdam(in_data, targets, batch_size=16):\n",
        "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
        "        batch_x = in_data[i:i + batch_size]\n",
        "        batch_y = targets[i:i + batch_size]\n",
        "        optimizer_RAdam.zero_grad()\n",
        "        output = net(batch_x)\n",
        "        loss = criterion(output.reshape(-1), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer_RAdam.step()\n",
        "    print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDppdtr8LZdS",
        "outputId": "a612e303-9baf-428a-ebf1-f37e279d436b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:06<00:00,  1.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:28<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6911, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:48<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6911, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:55<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6910, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:53<00:00,  1.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6909, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:54<00:00,  1.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6909, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:56<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6909, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:55<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6908, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:56<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6908, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 269/269 [03:57<00:00,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6908, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  train_one_epoch_RAdam(in_data, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw7qMqwRLpoa"
      },
      "outputs": [],
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJAFDY3PLpob"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = net(in_data_test).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqnqb9OaLpoc"
      },
      "outputs": [],
      "source": [
        "result = (output > 0.5) == targets_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8B2eBusLpoc",
        "outputId": "2eae7864-f016-4652-fb89-c23349e93eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5252477583765928"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.sum().item() / len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9m_yaasrDZk"
      },
      "source": [
        "### добавление скрытых слоёв"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evkdI9rHrVD1",
        "outputId": "38ad3632-f5cc-43a5-fcb3-5db15cef5fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net_1(\n",
            "  (lstm): LSTM(300, 100)\n",
            "  (Linear): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Добавим еще два скрытых слоя\n",
        "class Net_1(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net_1, self).__init__()\n",
        "        self.lstm = nn.LSTM(300, 100)\n",
        "        self.Linear = nn.Linear(100, 100)\n",
        "        self.Linear = nn.Linear(100, 100)\n",
        "        self.out = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings, (shortterm, longterm) = self.lstm(x.transpose(0, 1))\n",
        "        prediction = torch.sigmoid(self.out(longterm))\n",
        "        return prediction\n",
        "\n",
        "\n",
        "net_1 = Net_1()\n",
        "print(net_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CDeYwJd4WBi"
      },
      "outputs": [],
      "source": [
        "optimizer_RAdam_1 = optim.RAdam(net_1.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzX21gix4WBj"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpSDD8X0tNTp"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch_RAdam_1(in_data, targets, batch_size=16):\n",
        "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
        "        batch_x = in_data[i:i + batch_size]\n",
        "        batch_y = targets[i:i + batch_size]\n",
        "        optimizer_RAdam_1.zero_grad()\n",
        "        output = net_1(batch_x)\n",
        "        loss = criterion(output.reshape(-1), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer_RAdam_1.step()\n",
        "    print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IeIvQFItNTq",
        "outputId": "c4ad2c13-418f-4473-820b-3af471c307c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:27<00:00,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7120, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#for i in range(10): # включился лимит на ускоритель, поэтому делаю 1 эпоху, десять всё равно мало, для видимого результата надо добавлять больше 10 эпох.\n",
        "train_one_epoch_RAdam_1(in_data, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95iXY6bStNTq"
      },
      "outputs": [],
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smbXlGQVtNTr"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = net_1(in_data_test).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdXJtqFutNTr"
      },
      "outputs": [],
      "source": [
        "result = (output > 0.5) == targets_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z--C_8oftNTr",
        "outputId": "0b96add8-fce3-4776-fbc6-c2fee6c230c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5214723926380368"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "result.sum().item() / len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzxvNhmLFScM"
      },
      "source": [
        "### добавление функции активации скрытого слоя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8b0fd1-fdc7-4a5c-a6d9-83b59b7625c0",
        "id": "gjkCrnRU2cXH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net_1(\n",
            "  (lstm): LSTM(300, 100)\n",
            "  (Linear): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (ReLU): ReLU()\n",
            "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Добавим функцию активации скрытого слоя ReLU\n",
        "class Net_1(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net_1, self).__init__()\n",
        "        self.lstm = nn.LSTM(300, 100)\n",
        "        self.Linear = nn.Linear(100, 100)\n",
        "        self.ReLU=nn.ReLU()\n",
        "        self.Linear = nn.Linear(100, 100)\n",
        "        self.ReLU=nn.ReLU()\n",
        "        self.out = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings, (shortterm, longterm) = self.lstm(x.transpose(0, 1))\n",
        "        prediction = torch.sigmoid(self.out(longterm))\n",
        "        return prediction\n",
        "\n",
        "\n",
        "net_1 = Net_1()\n",
        "print(net_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtIFGVwG2cXK"
      },
      "outputs": [],
      "source": [
        "optimizer_RAdam_1 = optim.RAdam(net_1.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9INi_91W2cXM"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f1kud3m2cXN"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch_RAdam_1(in_data, targets, batch_size=16):\n",
        "    for i in tqdm(range(0, in_data.shape[0], batch_size)):\n",
        "        batch_x = in_data[i:i + batch_size]\n",
        "        batch_y = targets[i:i + batch_size]\n",
        "        optimizer_RAdam_1.zero_grad()\n",
        "        output = net_1(batch_x)\n",
        "        loss = criterion(output.reshape(-1), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer_RAdam_1.step()\n",
        "    print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbde602-92c8-4e2d-bd3e-1b24865dd9f5",
        "id": "FVkA2jic2cXO"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:13<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7119, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:19<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7126, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:30<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7122, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:32<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7117, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:23<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7110, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:14<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7105, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:03<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7100, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:05<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7097, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:40<00:00,  1.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7092, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [06:04<00:00,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7088, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  train_one_epoch_RAdam_1(in_data, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnobLNIH2cXQ"
      },
      "outputs": [],
      "source": [
        "in_data_test = torch.tensor(X_test).float()\n",
        "targets_test = torch.tensor(y_test).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNNbRuFX2cXR"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = net_1(in_data_test).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1R16kDC2cXT"
      },
      "outputs": [],
      "source": [
        "result = (output > 0.5) == targets_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e585927-c2c8-4e6f-e1c6-b2937a1a2dce",
        "id": "lKMAmJfZ2cXU"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5214723926380368"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "result.sum().item() / len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### + 10 эпох"
      ],
      "metadata": {
        "id": "H7oyw2d-ESob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e67d3b8-43c3-40d5-a52f-cbfc4170b433",
        "id": "4D8qi6tzLFgS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:57<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7085, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:34<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7083, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [06:22<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7080, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [06:01<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7078, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:55<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7076, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:51<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7074, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [05:45<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7074, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [06:04<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7071, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [06:08<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7070, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 269/269 [06:31<00:00,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7069, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  train_one_epoch_RAdam_1(in_data, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ1sddN5LFgW"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = net_1(in_data_test).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeH_kR2SLFgX"
      },
      "outputs": [],
      "source": [
        "result = (output > 0.5) == targets_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5e3ef3-b6ca-4fba-f586-dec1d39d7a0c",
        "id": "I23h6AQgLFgZ"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5214723926380368"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "result.sum().item() / len(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}