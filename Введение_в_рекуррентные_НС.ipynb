{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "l4VAzKlG8aHj"
      },
      "source": [
        "## Тегирование нейронной части речи\n",
        "\n",
        "Теперь мы собираемся решить ту же проблему тегирования POS с помощью нейронных сетей.\n",
        "<img src=https://i.stack.imgur.com/6pdIT.png width=320>\n",
        "\n",
        "С точки зрения глубокого обучения это задача прогнозирования последовательности выходных данных, выровненной с последовательностью входных данных. Есть несколько задач, соответствующих этой формулировке:\n",
        "* Пометка части речи - вспомогательная задача для многих проблем НЛП\n",
        "* Распознавание именованных объектов — для чат-ботов и поисковых роботов\n",
        "* Предсказание структуры белка - для биоинформатики"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnu9D3YZoH2e"
      },
      "source": [
        "# %tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "65cK18WbGWDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yxFUBtb88aHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285a7fad-8b4e-4ee3-a004-71ca13dd4f3a"
      },
      "source": [
        "import nltk\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('brown') # скачиваем аннотированный корпус POS-тегов\n",
        "nltk.download('universal_tagset')\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal') # загружаем отмеченные предложения\n",
        "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
        "\n",
        "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "<ipython-input-2-06938dfeccdb>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq_OXuD38aHs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data,test_size=0.25,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAlXrDmU8aHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "99a2ca87-d2c5-45a1-b15e-772f2e0fdf36"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "def draw(sentence):\n",
        "    words,tags = zip(*sentence)\n",
        "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
        "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
        "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
        "\n",
        "\n",
        "draw(data[11])\n",
        "draw(data[10])\n",
        "draw(data[7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAViiL2C8aHt"
      },
      "source": [
        "### Построение словарей\n",
        "\n",
        "Как и раньше, нам нужно построить отображение токенов на целочисленные идентификаторы. На этот раз наша модель работает на уровне слов, обрабатывая одно слово за шаг RNN. Это означает, что нам придется иметь дело с гораздо большим словарным запасом..\n",
        "\n",
        "К счастью для нас, мы получаем эти слова только в качестве входных данных, то есть нам не нужно их предсказывать. Это означает, что мы можем иметь большой словарный запас бесплатно, используя встраивание слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXK_k-mo8aHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ae0857-6c45-4893-ea35-9b9ab8007a0a"
      },
      "source": [
        "from collections import Counter\n",
        "word_counts = Counter()\n",
        "for sentence in data:\n",
        "    words,tags = zip(*sentence)\n",
        "    word_counts.update(words)\n",
        "\n",
        "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
        "\n",
        "#let's measure what fraction of data words are in the dictionary\n",
        "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage = 0.92876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "T0hee8L88aHt"
      },
      "source": [
        "from collections import defaultdict\n",
        "word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n",
        "tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCmGbwpP8aHu"
      },
      "source": [
        "конвертировать слова и теги в матрицу фиксированного размера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "X7kx6jWn8aHu"
      },
      "source": [
        "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
        "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
        "\n",
        "    max_len = max_len or max(map(len,lines))\n",
        "    matrix = np.empty([len(lines), max_len],dtype)\n",
        "    matrix.fill(pad)\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
        "        matrix[i,:len(line_ix)] = line_ix\n",
        "\n",
        "    return matrix.T if time_major else matrix\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCaE-i5u8aHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2cfcca8-4225-4075-8902-39a9532a7fb9"
      },
      "source": [
        "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
        "\n",
        "print(\"Word ids:\")\n",
        "print(to_matrix(batch_words, word_to_id))\n",
        "print(\"Tag ids:\")\n",
        "print(to_matrix(batch_tags, tag_to_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word ids:\n",
            "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
            "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
            "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
            "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
            "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
            "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
            " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
            "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "Tag ids:\n",
            "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
            "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]\n",
            " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
            "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
            "   6  3  2 13  7]\n",
            " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_oK_i5Xa8aHv"
      },
      "source": [
        "### Построить модель\n",
        "\n",
        "В отличие от нашей предыдущей лаборатории, на этот раз мы сосредоточимся на высокоуровневом интерфейсе keras для рекуррентных нейронных сетей. Это настолько просто, насколько вы можете получить с помощью RNN, хотя и несколько ограничено для сложных задач, таких как seq2seq.\n",
        "\n",
        "По умолчанию все RNN keras применяются ко всей последовательности входных данных и создают последовательность скрытых состояний (return_sequences=True или только последнее скрытое состояние (return_sequences=False). Все повторения происходят под капотом.\n",
        "\n",
        "В верхней части нашей модели нам нужно применить плотный слой к каждому временному шагу независимо. На данный момент keras.layers.Dense по умолчанию применяется один раз ко всем объединенным временным шагам.Мы используем keras.layers.TimeDistributed для изменения плотного слоя, чтобы он применялся как к пакетной, так и к временной осям."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeb8d5j8aHv"
      },
      "source": [
        "import keras\n",
        "import keras.layers as L\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.SimpleRNN(64,return_sequences=True))\n",
        "\n",
        "#добавьте верхний слой, который предсказывает вероятности тегов\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj-wRS-iLFPI",
        "outputId": "871ffa26-3e4e-4548-86e0-8722536a9b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 50)          500100    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, None, 64)          7360      \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 14)         910       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 508,370\n",
            "Trainable params: 508,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbJqM2n8aHv"
      },
      "source": [
        "__Обучение:__  в этом случае мы не хотим заранее готовить весь набор обучающих данных. Основная причина в том, что длина каждого пакета зависит от максимальной длины предложения в пакете. Это оставляет нам два варианта: использовать собственный обучающий код, как на предыдущем семинаре, или использовать генераторы.\n",
        "\n",
        "В моделях Keras есть метод model.fit_generator, который принимает генератор Python, выдающий по одному пакету за раз. Но сначала нам нужно реализовать такой генератор:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.layers as L"
      ],
      "metadata": {
        "id": "oBke29nOY97-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kpeMsDi18aHw"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "BATCH_SIZE=32\n",
        "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
        "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
        "\n",
        "    while True:\n",
        "        indices = np.random.permutation(np.arange(len(sentences)))\n",
        "        for start in range(0,len(indices)-1,batch_size):\n",
        "            batch_indices = indices[start:start+batch_size]\n",
        "            batch_words,batch_tags = [],[]\n",
        "            for sent in sentences[batch_indices]:\n",
        "                words,tags = zip(*sent)\n",
        "                batch_words.append(words)\n",
        "                batch_tags.append(tags)\n",
        "\n",
        "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
        "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
        "\n",
        "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
        "            yield batch_words,batch_tags_1hot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYoR9vgn8aHw"
      },
      "source": [
        "__Обратные вызовы:__  еще одна вещь, которая нам нужна, — это измерение производительности модели. Сложность заключается не в том, чтобы считать точность после окончания предложения (при заполнении), а в том, чтобы убедиться, что мы считаем все данные проверки ровно один раз.\n",
        "Хотя нет ничего невозможного в том, чтобы убедить Keras сделать все это, мы можем также написать собственный обратный вызов, который сделает это.\n",
        "Обратные вызовы Keras позволяют вам написать собственный код, который будет запускаться один раз в каждую эпоху или каждый мини-пакет. Мы определим его через LambdaCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CC8woNtV8aHx"
      },
      "source": [
        "def compute_test_accuracy(model):\n",
        "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
        "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
        "\n",
        "    #predict tag probabilities of shape [batch,time,n_tags]\n",
        "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
        "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
        "\n",
        "    #compute accurary excluding padding\n",
        "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
        "    denominator = np.sum(test_words != 0)\n",
        "    return float(numerator)/denominator\n",
        "\n",
        "\n",
        "class EvaluateAccuracy(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        sys.stdout.flush()\n",
        "        print(\"\\nMeasuring validation accuracy...\")\n",
        "        acc = compute_test_accuracy(self.model)\n",
        "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
        "        sys.stdout.flush()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eJGEWu58aHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37085a4-1dcd-4dc4-a52b-3fd931e69d09"
      },
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1344/1343 [==============================] - ETA: 0s - loss: 0.2479\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 18ms/step\n",
            "\n",
            "Validation accuracy: 0.94102\n",
            "\n",
            "1343/1343 [==============================] - 130s 93ms/step - loss: 0.2479\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0579\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 17ms/step\n",
            "\n",
            "Validation accuracy: 0.94438\n",
            "\n",
            "1343/1343 [==============================] - 102s 76ms/step - loss: 0.0579\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0513\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 17ms/step\n",
            "\n",
            "Validation accuracy: 0.94664\n",
            "\n",
            "1343/1343 [==============================] - 96s 72ms/step - loss: 0.0513\n",
            "Epoch 4/5\n",
            "1343/1343 [============================>.] - ETA: 0s - loss: 0.0467\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 8s 17ms/step\n",
            "\n",
            "Validation accuracy: 0.94690\n",
            "\n",
            "1343/1343 [==============================] - 95s 71ms/step - loss: 0.0467\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0430\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 9s 20ms/step\n",
            "\n",
            "Validation accuracy: 0.94693\n",
            "\n",
            "1343/1343 [==============================] - 96s 72ms/step - loss: 0.0430\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f42682eb790>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTN7C34V8aHy"
      },
      "source": [
        "Измерьте окончательную точность на всем тестовом наборе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgxnYB68aHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1918f9b4-70f3-48d7-b71d-672ff4caef44"
      },
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"Final accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.94, \"Keras has gone on a rampage again, please contact course staff.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 7s 16ms/step\n",
            "Final accuracy: 0.94693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5Prr4I8aHy"
      },
      "source": [
        "### Двунаправленный\n",
        "\n",
        "Поскольку мы анализируем полную последовательность, мы можем смотреть на будущие данные. Простой способ добиться этого — двигаться в обоих направлениях одновременно, создавая __двунаправленную RNN__.\n",
        "\n",
        "В Keras вы можете добиться этого как вручную (используя два LSTM и Concatenate), так и используя __keras.layers.Bidirectional__.\n",
        "\n",
        "Он работает так же, как TimeDistributed, который мы видели раньше: вы оборачиваете его вокруг рекуррентного слоя (сейчас SimpleRNN, а позже LSTM/GRU), и он фактически создает два слоя под капотом.\n",
        "\n",
        "Ваша первая задача — использовать такой слой, как наш POS-тегер."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Определите модель, использующую двунаправленный SimpleRNN\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(L.InputLayer([None], dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.Bidirectional(L.SimpleRNN(64, return_sequences = True)))\n",
        "\n",
        "#добавьте верхний слой, который предсказывает вероятности тегов\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)\n"
      ],
      "metadata": {
        "id": "T1kXK2nwE_K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJrYSCsFLqx",
        "outputId": "3662cf40-acab-4b07-cb3f-0a38eae4909e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 50)          500100    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        14720     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 14)         1806      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 516,626\n",
            "Trainable params: 516,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5qMaNv5FSXQ",
        "outputId": "22a858bb-051c-4c35-b179-237a07929ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e75a6e7fae6a>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.2052\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 15s 33ms/step\n",
            "\n",
            "Validation accuracy: 0.95479\n",
            "\n",
            "1343/1343 [==============================] - 224s 162ms/step - loss: 0.2052\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0435\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 13s 29ms/step\n",
            "\n",
            "Validation accuracy: 0.96054\n",
            "\n",
            "1343/1343 [==============================] - 161s 120ms/step - loss: 0.0435\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0356\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 13s 29ms/step\n",
            "\n",
            "Validation accuracy: 0.96230\n",
            "\n",
            "1343/1343 [==============================] - 171s 127ms/step - loss: 0.0356\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0299\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 14s 31ms/step\n",
            "\n",
            "Validation accuracy: 0.96221\n",
            "\n",
            "1343/1343 [==============================] - 157s 117ms/step - loss: 0.0299\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - ETA: 0s - loss: 0.0252\n",
            "Measuring validation accuracy...\n",
            "448/448 [==============================] - 13s 29ms/step\n",
            "\n",
            "Validation accuracy: 0.96024\n",
            "\n",
            "1343/1343 [==============================] - 155s 115ms/step - loss: 0.0252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc4604e93d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
        "print(\"Well done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OTGtMgUHOVb",
        "outputId": "57fc60dc-249e-4b85-eb68-e79c00f208ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448/448 [==============================] - 13s 30ms/step\n",
            "\n",
            "Final accuracy: 0.96024\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF1T00yr8RvM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}